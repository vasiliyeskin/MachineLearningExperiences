{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vasiliyeskin/MachineLearningExperiences/blob/master/fast_stable_diffusion_AUTOMATIC1111.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47kV9o1Ni8GH"
      },
      "source": [
        "# **Notebook From https://github.com/TheLastBen/fast-stable-diffusion, if you encounter any issues, feel free to discuss them.** [Support](https://ko-fi.com/thelastben)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Y9EBc437WDOs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "03d16476-4f07-4369-ec7d-d66e33f9be18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0;33mConnecting...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-57b988abe919>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\u001b[0;33mConnecting...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mShared_Drive\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m\"\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/gdrive/Shareddrives\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    130\u001b[0m   )\n\u001b[1;32m    131\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "#@markdown # Connect Google Drive\n",
        "from google.colab import drive\n",
        "from IPython.display import clear_output\n",
        "import ipywidgets as widgets\n",
        "import os\n",
        "\n",
        "def inf(msg, style, wdth): inf = widgets.Button(description=msg, disabled=True, button_style=style, layout=widgets.Layout(min_width=wdth));display(inf)\n",
        "Shared_Drive = \"\" #@param {type:\"string\"}\n",
        "#@markdown - Leave empty if you're not using a shared drive\n",
        "\n",
        "print(\"\u001b[0;33mConnecting...\")\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "if Shared_Drive!=\"\" and os.path.exists(\"/content/gdrive/Shareddrives\"):\n",
        "  mainpth=\"Shareddrives/\"+Shared_Drive \n",
        "else:\n",
        "  mainpth=\"MyDrive\"\n",
        "\n",
        "clear_output()\n",
        "inf('\\u2714 Done','success', '50px')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "cellView": "form",
        "id": "CFWtw-6EPrKi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "852f3d4a6c7448c7ba8dc133d7553ffa",
            "bf021d36d0024b398b944fce0f8e28a5",
            "638cc306969c4a8cbe5ed094123bde72"
          ]
        },
        "outputId": "b8ae3cfb-e740-4287-af99-d7a094a6b638"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(button_style='success', description='✔ Done', disabled=True, layout=Layout(min_width='50px'), style=But…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "852f3d4a6c7448c7ba8dc133d7553ffa"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@markdown # Install/Update AUTOMATIC1111 repo\n",
        "from IPython.utils import capture\n",
        "from IPython.display import clear_output\n",
        "from subprocess import getoutput\n",
        "import ipywidgets as widgets\n",
        "import sys\n",
        "import fileinput\n",
        "import os\n",
        "import time\n",
        "import base64\n",
        "\n",
        "Use_Latest_Working_Commit= True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown - Use the pre-major A1111 update commit to avoid bugs while the repo is fixed\n",
        "\n",
        "blasphemy=base64.b64decode((\"d2VidWk=\").encode('ascii')).decode('ascii')\n",
        "\n",
        "if not os.path.exists(\"/content/gdrive\"):\n",
        "  print('\u001b[1;31mGdrive not connected, using colab storage ...')\n",
        "  time.sleep(4)\n",
        "  mainpth=\"MyDrive\"\n",
        "  !mkdir -p /content/gdrive/$mainpth\n",
        "  Shared_Drive=\"\"\n",
        "  \n",
        "if Shared_Drive!=\"\" and not os.path.exists(\"/content/gdrive/Shareddrives\"):\n",
        "  print('\u001b[1;31mShared drive not detected, using default MyDrive')\n",
        "  mainpth=\"MyDrive\"\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  def inf(msg, style, wdth): inf = widgets.Button(description=msg, disabled=True, button_style=style, layout=widgets.Layout(min_width=wdth));display(inf)\n",
        "  fgitclone = \"git clone --depth 1\"\n",
        "  %mkdir -p /content/gdrive/$mainpth/sd\n",
        "  %cd /content/gdrive/$mainpth/sd\n",
        "  !git clone -q --branch master https://github.com/AUTOMATIC1111/stable-diffusion-$blasphemy\n",
        "  !mkdir -p /content/gdrive/$mainpth/sd/stable-diffusion-$blasphemy/cache/\n",
        "  os.environ['TRANSFORMERS_CACHE']=f\"/content/gdrive/{mainpth}/sd/stable-diffusion-\"+blasphemy+\"/cache\"\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd /content/gdrive/$mainpth/sd/stable-diffusion-$blasphemy/\n",
        "  !git reset --hard\n",
        "  time.sleep(1)\n",
        "  !rm webui.sh\n",
        "  !git pull\n",
        "  if Use_Latest_Working_Commit:\n",
        "    !git fetch --unshallow\n",
        "    !git checkout a9eab236d7e8afa4d6205127904a385b2c43bb24\n",
        "    !pip install gradio==3.16.2 --no-deps -qq\n",
        "  else:\n",
        "    !pip install gradio==3.23 --no-deps -qq\n",
        "clear_output()\n",
        "inf('\\u2714 Done','success', '50px')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "cellView": "form",
        "id": "ZGV_5H4xrOSp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "9745dd2e4ca8469aa13644d0222becca",
            "766b8b8b86c240c3b60a79b37e59046b",
            "700bc180578540d394c6eb8dffd2d6b7"
          ]
        },
        "outputId": "a8564785-02b6-4361-9769-6a4e02c4b5ed"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(button_style='success', description='✔ Done', disabled=True, layout=Layout(min_width='50px'), style=But…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9745dd2e4ca8469aa13644d0222becca"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@markdown # Requirements\n",
        "\n",
        "print('\u001b[1;32mInstalling requirements...')\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd /content/ \n",
        "  !wget -q -i https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dependencies/A1111.txt\n",
        "  !dpkg -i *.deb\n",
        "  if not os.path.exists('/content/gdrive/'+mainpth+'/sd/stablediffusion'):\n",
        "    !tar -C /content/gdrive/$mainpth --zstd -xf sd_rep.tar.zst\n",
        "  !tar -C / --zstd -xf gcolabdeps.tar.zst\n",
        "  !rm *.deb | rm *.zst | rm *.txt\n",
        "  %env LD_PRELOAD=libtcmalloc.so\n",
        "  os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "  os.environ['PYTHONWARNINGS'] = 'ignore'\n",
        "  if Use_Latest_Working_Commit:\n",
        "    !pip install gradio==3.16.2 --no-deps -qq\n",
        "  else:\n",
        "    !pip install gradio==3.23 --no-deps -qq\n",
        "\n",
        "clear_output()\n",
        "inf('\\u2714 Done','success', '50px')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "cellView": "form",
        "id": "p4wj_txjP3TC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "687c5aa5c25f453ea759699f02cc3ed8",
            "d7f17c693e73462c96f8216ac1318683",
            "435109afd3b84a30a09bf8a05a9ce511"
          ]
        },
        "outputId": "bca9d133-5e45-493c-c831-bea3cc988dd8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(button_style='success', description='✔ Done', disabled=True, layout=Layout(min_width='50px'), style=But…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "687c5aa5c25f453ea759699f02cc3ed8"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@markdown # Model Download/Load\n",
        "Model_Version = \"V2.1-512px\" #@param [ \"1.5\", \"v1.5 Inpainting \", \"V2.1-512px\", \"V2.1-768px\"]\n",
        "\n",
        "Redownload_the_original_model = False #@param {type:\"boolean\"}\n",
        "\n",
        "def rmv():\n",
        "  !wget -q -O /content/gdrive/$mainpth/sd/stable-diffusion-$blasphemy/models/Stable-diffusion/model.ckpt https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/precompiled/README.md\n",
        "  !mv /content/gdrive/$mainpth/sd/stable-diffusion-$blasphemy/models/Stable-diffusion/model.ckpt /content/gdrive/$mainpth/sd/stable-diffusion-$blasphemy/models/Stable-diffusion/trashfile.f\n",
        "  time.sleep(2)\n",
        "  !rm /content/gdrive/$mainpth/sd/stable-diffusion-$blasphemy/models/Stable-diffusion/trashfile.f\n",
        "  clear_output()\n",
        "\n",
        "if Redownload_the_original_model:\n",
        "  with capture.capture_output() as cap:\n",
        "    rmv()\n",
        "\n",
        "#@markdown Or\n",
        "Path_to_MODEL = \"\" #@param {type:\"string\"}\n",
        "#@markdown - Insert the full path of your trained model or to a folder containing multiple models\n",
        "\n",
        "#@markdown Or\n",
        "MODEL_LINK = \"\" #@param {type:\"string\"}\n",
        "safetensors = False #@param {type:\"boolean\"}\n",
        "Use_temp_storage = False #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "\n",
        "def newmdl():\n",
        "\n",
        "    if not os.path.exists('/content/gdrive/'+mainpth+'/sd/stable-diffusion-'+blasphemy+'/models/Stable-diffusion/model.ckpt'):\n",
        "      %cd /content/\n",
        "      clear_output()\n",
        "      !git init\n",
        "      !git lfs install --system --skip-repo\n",
        "      !$fgitclone --branch fp16 \"https://huggingface.co/runwayml/stable-diffusion-v1-5\"\n",
        "      if os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "        !wget -q -O stable-diffusion-v1-5/vae/diffusion_pytorch_model.bin https://huggingface.co/stabilityai/sd-vae-ft-mse/resolve/main/diffusion_pytorch_model.bin\n",
        "        !wget -q -O convertosd.py https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertosd.py\n",
        "        !sed -i '201s@.*@    model_path = \"/content/stable-diffusion-v1-5\"@' /content/convertosd.py\n",
        "        !sed -i '202s@.*@    checkpoint_path= \"/content/gdrive/{mainpth}/sd/stable-diffusion-{blasphemy}/models/Stable-diffusion/model.ckpt\"@' /content/convertosd.py\n",
        "        clear_output()       \n",
        "        !python /content/convertosd.py\n",
        "        !rm /content/convertosd.py\n",
        "        if os.path.exists('/content/gdrive/'+mainpth+'/sd/stable-diffusion-'+blasphemy+'/models/Stable-diffusion/model.ckpt'):\n",
        "          model='/content/gdrive/'+mainpth+'/sd/stable-diffusion-'+blasphemy+'/models/Stable-diffusion/model.ckpt'\n",
        "          clear_output()\n",
        "          inf('\\u2714 Done','success', '50px')\n",
        "        else:\n",
        "          inf('\\u2718 Something went wrong, try again','danger', \"250px\")\n",
        "      else:\n",
        "        inf('\\u2718 Something went wrong','danger', \"200px\")\n",
        "\n",
        "    else:\n",
        "      model='/content/gdrive/'+mainpth+'/sd/stable-diffusion-'+blasphemy+'/models/Stable-diffusion/model.ckpt'\n",
        "      clear_output()\n",
        "      inf('\\u2714 Model already exists, check the box \"Redownload_the_original_model\" to redownload/download the V1.5','primary', '700px')\n",
        "\n",
        "    if os.path.exists('/content/.git'):\n",
        "      !rm -r /content/.git\n",
        "\n",
        "    if os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "      !rm -r /content/stable-diffusion-v1-5\n",
        "\n",
        "    return model\n",
        "\n",
        "def V2():\n",
        "\n",
        "    if not os.path.exists('/content/gdrive/'+mainpth+'/sd/stable-diffusion-'+blasphemy+'/models/Stable-diffusion/model.ckpt'):\n",
        "      %cd /content/\n",
        "      clear_output()\n",
        "      !mkdir \"/content/stable-diffusion-V2\"\n",
        "      %cd \"/content/stable-diffusion-V2\"\n",
        "      !git init\n",
        "      !git lfs install --system --skip-repo\n",
        "      if Model_Version == \"V2.1-768px\":\n",
        "        !git remote add -f origin  \"https://huggingface.co/stabilityai/stable-diffusion-2-1\"\n",
        "      elif Model_Version == \"V2.1-512px\":\n",
        "        !git remote add -f origin  \"https://huggingface.co/stabilityai/stable-diffusion-2-1-base\"\n",
        "      !git config core.sparsecheckout true\n",
        "      !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nfeature_extractor\\nmodel_index.json\\n!*.safetensors\" > .git/info/sparse-checkout\n",
        "      !git pull origin fp16\n",
        "      %cd /content\n",
        "      !wget -O convertosdv2.py https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertosdv2.py\n",
        "      clear_output()\n",
        "      !python /content/convertosdv2.py --fp16 /content/stable-diffusion-V2 /content/gdrive/$mainpth/sd/stable-diffusion-$blasphemy/models/Stable-diffusion/model.ckpt\n",
        "      !rm /content/convertosdv2.py\n",
        "      if os.path.exists('/content/gdrive/'+mainpth+'/sd/stable-diffusion-'+blasphemy+'/models/Stable-diffusion/model.ckpt'):\n",
        "        model='/content/gdrive/'+mainpth+'/sd/stable-diffusion-'+blasphemy+'/models/Stable-diffusion/model.ckpt'\n",
        "        clear_output()\n",
        "        inf('\\u2714 Done','success', '50px')\n",
        "      else:\n",
        "        inf('\\u2718 Something went wrong, try again','danger', \"250px\")\n",
        "\n",
        "    else:\n",
        "      model='/content/gdrive/'+mainpth+'/sd/stable-diffusion-'+blasphemy+'/models/Stable-diffusion/model.ckpt'\n",
        "      clear_output()\n",
        "      inf('\\u2714 Model already exists, check the box \"Redownload_the_original_model\" to redownload/download the V2','primary', '700px')\n",
        "\n",
        "    if os.path.exists('/content/.git'):\n",
        "      !rm -r /content/.git\n",
        "      !rm -r /content/convertosdv2.py\n",
        "    if os.path.exists('/content/stable-diffusion-V2'):\n",
        "      !rm -r /content/stable-diffusion-V2\n",
        "\n",
        "    return model\n",
        "\n",
        "def inpmdl():\n",
        "\n",
        "    if not os.path.exists('/content/gdrive/'+mainpth+'/sd/stable-diffusion-'+blasphemy+'/models/Stable-diffusion/sd-v1-5-inpainting.ckpt'):\n",
        "      %cd /content/\n",
        "      clear_output()\n",
        "      !git init\n",
        "      !git lfs install --system --skip-repo\n",
        "      !$fgitclone --branch fp16 \"https://huggingface.co/runwayml/stable-diffusion-inpainting\"\n",
        "      if os.path.exists('/content/stable-diffusion-inpainting'):\n",
        "        !$fgitclone \"https://huggingface.co/stabilityai/sd-vae-ft-mse\"\n",
        "        !rm -r /content/stable-diffusion-inpainting/vae\n",
        "        !mv /content/sd-vae-ft-mse /content/stable-diffusion-inpainting/vae        \n",
        "        !wget -O convertosd.py https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertosd.py\n",
        "        !sed -i '201s@.*@    model_path = \"/content/stable-diffusion-inpainting\"@' /content/convertosd.py\n",
        "        !sed -i '202s@.*@    checkpoint_path= \"/content/gdrive/{mainpth}/sd/stable-diffusion-{blasphemy}/models/Stable-diffusion/sd-v1-5-inpainting.ckpt\"@' /content/convertosd.py\n",
        "        clear_output()       \n",
        "        !python /content/convertosd.py\n",
        "        !rm /content/convertosd.py\n",
        "        if os.path.exists('/content/gdrive/'+mainpth+'/sd/stable-diffusion-'+blasphemy+'/models/Stable-diffusion/sd-v1-5-inpainting.ckpt'):\n",
        "          model='/content/gdrive/'+mainpth+'/sd/stable-diffusion-'+blasphemy+'/models/Stable-diffusion/sd-v1-5-inpainting.ckpt'\n",
        "          clear_output()\n",
        "          inf('\\u2714 Done','success', '50px')\n",
        "        else:\n",
        "          inf('\\u2718 Something went wrong, try again','danger', \"250px\")\n",
        "      else:\n",
        "        inf('\\u2718 Something went wrong','danger', \"200px\")\n",
        "\n",
        "\n",
        "    else:\n",
        "      model='/content/gdrive/'+mainpth+'/sd/stable-diffusion-'+blasphemy+'/models/Stable-diffusion/sd-v1-5-inpainting.ckpt'\n",
        "      clear_output()\n",
        "      inf('\\u2714 inpainting model already exists','primary', '250px')\n",
        "\n",
        "    if os.path.exists('/content/.git'):\n",
        "      !rm -r /content/.git\n",
        "\n",
        "    if os.path.exists('/content/stable-diffusion-inpainting'):\n",
        "      !rm -r /content/stable-diffusion-inpainting\n",
        "\n",
        "    return model\n",
        "\n",
        "if (Path_to_MODEL !=''):\n",
        "  if os.path.exists(str(Path_to_MODEL)):\n",
        "    inf('\\u2714 Using the trained model.','success', '200px')\n",
        "\n",
        "  else:\n",
        "      while not os.path.exists(str(Path_to_MODEL)):\n",
        "        inf('\\u2718 Wrong path, use the colab file explorer to copy the path : ','danger', \"400px\")\n",
        "        Path_to_MODEL=input()\n",
        "      if os.path.exists(str(Path_to_MODEL)):\n",
        "        inf('\\u2714 Using the trained model.','success', '200px')\n",
        "\n",
        "  model=Path_to_MODEL\n",
        "\n",
        "elif MODEL_LINK != \"\":\n",
        "  gdrv='/content/gdrive/'+mainpth+'/sd/stable-diffusion-'+blasphemy+'/models/Stable-diffusion'\n",
        "  tmp=\"/content\"\n",
        "  pth=tmp if Use_temp_storage else gdrv\n",
        "  %cd $pth\n",
        "  clear_output()\n",
        "  if not safetensors:\n",
        "    modelname=\"model.ckpt\"\n",
        "  else:\n",
        "    modelname=\"model.safetensors\"\n",
        "  !gdown --fuzzy -O $modelname \"$MODEL_LINK\"\n",
        "  if os.path.exists(f'{pth}/{modelname}') and os.path.getsize(f'{pth}/{modelname}') > 1810671599:    \n",
        "      model=f'{pth}/{modelname}'\n",
        "      clear_output()\n",
        "      inf('\\u2714 Model downloaded, using the trained model.','success', '350px')\n",
        "  else:\n",
        "    if Use_temp_storage:\n",
        "      !rm $pth/$modelname\n",
        "    else:\n",
        "      rmv()\n",
        "    inf('\\u2718 Wrong link, check that the link is valid','danger', \"300px\")\n",
        "\n",
        "\n",
        "elif Model_Version==\"1.5\":\n",
        "  model=newmdl()\n",
        "\n",
        "elif Model_Version==\"V2.1-512px\" or Model_Version==\"V2.1-768px\":\n",
        "  model=V2()\n",
        "\n",
        "else:\n",
        "   model=inpmdl()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "cellView": "form",
        "id": "zC3Rz1b2TBcB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "4ebfd7f28576471a984a025826cd8ca9",
            "d29f63eb692c416ab3610490e21278a7",
            "424945226ce64cfd9b9d1e67c445c5d0"
          ]
        },
        "outputId": "79a2852e-42b3-4b5b-afeb-2cee7d5c80f4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(button_style='success', description='✔ Done', disabled=True, layout=Layout(min_width='50px'), style=But…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ebfd7f28576471a984a025826cd8ca9"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@markdown # ControlNet\n",
        "from torch.hub import download_url_to_file\n",
        "from urllib.parse import urlparse\n",
        "import re\n",
        "from subprocess import run\n",
        "\n",
        "Model = \"Canny\" #@param [ \"None\", \"All (21GB)\", \"Canny\", \"Depth\", \"Lineart\", \"MLSD\", \"Normal\", \"OpenPose\", \"Scribble\", \"Seg\", \"ip2p\", \"Shuffle\", \"Inpaint\", \"Softedge\", \"Lineart_Anime\", \"Tile\", \"T2iadapter_Models\"]\n",
        "\n",
        "v2_Model = \"Canny\" #@param [ \"None\", \"All\", \"Canny\", \"Depth\", \"HED\", \"OpenPose\", \"Scribble\"]\n",
        "\n",
        "#@markdown - Download/update ControlNet extension and its models\n",
        "\n",
        "def download(url, model_dir):\n",
        "\n",
        "    filename = os.path.basename(urlparse(url).path)\n",
        "    pth = os.path.abspath(os.path.join(model_dir, filename))\n",
        "    if not os.path.exists(pth):\n",
        "        print('Downloading: '+os.path.basename(url))\n",
        "        download_url_to_file(url, pth, hash_prefix=None, progress=True)\n",
        "    else:\n",
        "      print(f\"\u001b[1;32mThe model {filename} already exists\u001b[0m\")\n",
        "\n",
        "Canny='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_canny.pth'\n",
        "Depth='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11f1p_sd15_depth.pth'\n",
        "Lineart='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_lineart.pth'\n",
        "MLSD='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_mlsd.pth'\n",
        "Normal='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_normalbae.pth'\n",
        "OpenPose='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_openpose.pth'\n",
        "Scribble='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_scribble.pth'\n",
        "Seg='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_seg.pth'\n",
        "ip2p='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11e_sd15_ip2p.pth'\n",
        "Shuffle='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11e_sd15_shuffle.pth'\n",
        "Inpaint='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_inpaint.pth'\n",
        "Softedge='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_softedge.pth'\n",
        "Lineart_Anime='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15s2_lineart_anime.pth'\n",
        "Tile='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11u_sd15_tile.pth'\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd /content/gdrive/$mainpth/sd/stable-diffusion-$blasphemy/extensions\n",
        "  if not os.path.exists(\"sd-webui-controlnet\"):\n",
        "    !git clone https://github.com/Mikubill/sd-$blasphemy-controlnet.git\n",
        "    %cd /content\n",
        "  else:\n",
        "    %cd sd-webui-controlnet\n",
        "    !git reset --hard\n",
        "    !git pull\n",
        "    %cd /content\n",
        "\n",
        "mdldir='/content/gdrive/'+mainpth+'/sd/stable-diffusion-'+blasphemy+'/extensions/sd-webui-controlnet/models'\n",
        "for filename in os.listdir(mdldir):\n",
        "  if \"_sd14v1\" in filename:\n",
        "    renamed = re.sub(\"_sd14v1\", \"-fp16\", filename)\n",
        "    os.rename(os.path.join(mdldir, filename), os.path.join(mdldir, renamed))\n",
        "\n",
        "!wget -q -O CN_models.txt https://github.com/TheLastBen/fast-stable-diffusion/raw/main/AUTOMATIC1111_files/CN_models.txt\n",
        "!wget -q -O CN_models_v2.txt https://github.com/TheLastBen/fast-stable-diffusion/raw/main/AUTOMATIC1111_files/CN_models_v2.txt\n",
        "\n",
        "with open(\"CN_models.txt\", 'r') as f:\n",
        "  mdllnk = f.read().splitlines()\n",
        "with open(\"CN_models_v2.txt\", 'r') as d:\n",
        "  mdllnk_v2 = d.read().splitlines()\n",
        "\n",
        "!rm CN_models.txt CN_models_v2.txt\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  cfgnames=[os.path.basename(url).split('.')[0]+'.yaml' for url in mdllnk_v2]\n",
        "  %cd /content/gdrive/$mainpth/sd/stable-diffusion-$blasphemy/extensions/sd-webui-controlnet/models\n",
        "  for name in cfgnames:\n",
        "      run(['cp', 'cldm_v21.yaml', name])\n",
        "  %cd /content\n",
        "\n",
        "if Model == \"All (21GB)\": \n",
        "  for lnk in mdllnk:\n",
        "      download(lnk, mdldir)\n",
        "  clear_output()\n",
        "\n",
        "elif Model == \"T2iadapter_Models\":\n",
        "  mdllnk=list(filter(lambda x: 't2i' in x, mdllnk))\n",
        "  for lnk in mdllnk:\n",
        "      download(lnk, mdldir)\n",
        "  clear_output()\n",
        "\n",
        "elif Model == \"None\":\n",
        "    pass\n",
        "    clear_output()\n",
        "\n",
        "else:\n",
        "  download(globals()[Model], mdldir)\n",
        "  clear_output()\n",
        "\n",
        "Canny='https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_canny.safetensors'\n",
        "Depth='https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_depth.safetensors'\n",
        "HED='https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_hed.safetensors'\n",
        "OpenPose='https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_openpose.safetensors'\n",
        "Scribble='https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_scribble.safetensors'\n",
        "\n",
        "if v2_Model == \"All\":\n",
        "  for lnk_v2 in mdllnk_v2:\n",
        "      download(lnk_v2, mdldir)\n",
        "  clear_output()\n",
        "  inf('\\u2714 Done','success', '50px')\n",
        "\n",
        "elif v2_Model == \"None\":\n",
        "    pass\n",
        "    clear_output()\n",
        "    inf('\\u2714 Done','success', '50px')\n",
        "\n",
        "else:\n",
        "  download(globals()[v2_Model], mdldir)\n",
        "  clear_output()\n",
        "  inf('\\u2714 Done','success', '50px')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "PjzwxTkPSPHf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d489e6db-4d36-42ac-e96f-f012d9fdea63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ControlNet v1.1.101\n",
            "ControlNet v1.1.101\n",
            "Calculating sha256 for /content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/model.ckpt: 1976397d3dafc2505ee293294b09a8e6c1a736b93f40f8b2d05e6df4e2457316\n",
            "Loading weights [1976397d3d] from /content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/model.ckpt\n",
            "Creating model from config: /content/gdrive/MyDrive/sd/stablediffusion/configs/stable-diffusion/v2-inference.yaml\n",
            "LatentDiffusion: Running in eps-prediction mode\n",
            "DiffusionWrapper has 865.91 M params.\n",
            "Applying scaled dot product cross attention optimization.\n",
            "Textual inversion embeddings loaded(0): \n",
            "Model loaded in 37.1s (calculate hash: 16.4s, load weights from disk: 10.0s, find config: 4.3s, create model: 0.3s, apply weights to model: 3.2s, apply half(): 1.6s, move model to device: 1.1s).\n",
            "Running on public URL: https://dce44822-5138-46c8.gradio.live\n",
            "\u001b[32m✔ Connected\n",
            "Startup time: 65.4s (import gradio: 3.0s, import ldm: 5.0s, other imports: 3.6s, load scripts: 2.7s, load SD checkpoint: 37.1s, create ui: 0.8s, gradio launch: 12.9s).\n",
            "100% 20/20 [00:08<00:00,  2.35it/s]\n",
            "100% 20/20 [00:03<00:00,  6.53it/s]\n",
            "100% 20/20 [00:03<00:00,  6.48it/s]\n",
            "100% 20/20 [00:43<00:00,  2.17s/it]\n",
            "100% 20/20 [00:11<00:00,  1.67it/s]\n",
            "100% 20/20 [01:16<00:00,  3.81s/it]\n",
            "100% 20/20 [01:08<00:00,  3.44s/it]\n",
            "100% 20/20 [00:43<00:00,  2.17s/it]\n",
            "100% 20/20 [00:38<00:00,  1.93s/it]\n",
            "100% 20/20 [00:39<00:00,  1.95s/it]\n",
            "Data shape for PLMS sampling is (4, 4, 99, 64)\n",
            "Running PLMS Sampling with 20 timesteps\n",
            "PLMS Sampler100% 20/20 [00:19<00:00,  1.01it/s]\n",
            "Data shape for PLMS sampling is (4, 4, 99, 64)\n",
            "Running PLMS Sampling with 91 timesteps\n",
            "PLMS Sampler100% 91/91 [01:27<00:00,  1.04it/s]\n",
            "100% 73/73 [01:10<00:00,  1.04it/s]\n",
            "100% 40/40 [00:38<00:00,  1.05it/s]\n",
            "100% 40/40 [00:39<00:00,  1.02it/s]\n",
            "Prompt matrix will create 1 images using a total of 1 batches.\n",
            "Loading model: control_v11p_sd15_canny [d14c016b]\n",
            "Loaded state_dict from [/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/models/control_v11p_sd15_canny.pth]\n",
            "Loading config: /content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/models/control_v11p_sd15_canny.yaml\n",
            "ControlNet model control_v11p_sd15_canny [d14c016b] loaded.\n",
            "Error running process: /content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/controlnet.py\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/scripts.py\", line 409, in process\n",
            "    script.process(p, *script_args)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/controlnet.py\", line 1058, in process\n",
            "    tmp_seed = int(p.all_seeds[0] if p.seed == -1 else max(int(p.seed),0))\n",
            "TypeError: int() argument must be a string, a bytes-like object or a number, not 'list'\n",
            "\n",
            "  0% 0/40 [00:00<?, ?it/s]\n",
            "Error completing request\n",
            "Arguments: ('task(rae3tkts0o8562f)', 'sunny day, mixpunck USSR future alien car, fantastic soviet union sity background, elien landscape, trending on artstation, sharp focus, studio photo, intricate details, highly detailed, by greg rutkowski, red ', '', [], 40, 1, False, False, 1, 4, 6, 196470314.0, -1.0, 0, 0, 0, False, 796, 512, False, 0.7, 2, 'Latent', 0, 0, 0, [], 1, <controlnet.py.UiControlNetUnit object at 0x7f0b8ba59970>, False, False, 'positive', 'comma', 0, False, False, '', 1, '', 0, '', 0, '', True, False, False, False, 0, None, False, 50) {}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/call_queue.py\", line 56, in f\n",
            "    res = list(func(*args, **kwargs))\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/call_queue.py\", line 37, in f\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/txt2img.py\", line 53, in txt2img\n",
            "    processed = modules.scripts.scripts_txt2img.run(p, *args)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/scripts.py\", line 399, in run\n",
            "    processed = script.run(p, *script_args)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/scripts/prompt_matrix.py\", line 100, in run\n",
            "    processed = process_images(p)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/processing.py\", line 486, in process_images\n",
            "    res = process_images_inner(p)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/batch_hijack.py\", line 42, in processing_process_images_hijack\n",
            "    return getattr(processing, '__controlnet_original_process_images_inner')(p, *args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/processing.py\", line 636, in process_images_inner\n",
            "    samples_ddim = p.sample(conditioning=c, unconditional_conditioning=uc, seeds=seeds, subseeds=subseeds, subseed_strength=p.subseed_strength, prompts=prompts)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/processing.py\", line 836, in sample\n",
            "    samples = self.sampler.sample(self, x, conditioning, unconditional_conditioning, image_conditioning=self.txt2img_image_conditioning(x))\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/sd_samplers_kdiffusion.py\", line 351, in sample\n",
            "    samples = self.launch_sampling(steps, lambda: self.func(self.model_wrap_cfg, x, extra_args={\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/sd_samplers_kdiffusion.py\", line 227, in launch_sampling\n",
            "    return func()\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/sd_samplers_kdiffusion.py\", line 351, in <lambda>\n",
            "    samples = self.launch_sampling(steps, lambda: self.func(self.model_wrap_cfg, x, extra_args={\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/src/k-diffusion/k_diffusion/sampling.py\", line 128, in sample_euler\n",
            "    denoised = model(x, sigma_hat * s_in, **extra_args)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/sd_samplers_kdiffusion.py\", line 119, in forward\n",
            "    x_out = self.inner_model(x_in, sigma_in, cond={\"c_crossattn\": [cond_in], \"c_concat\": [image_cond_in]})\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/src/k-diffusion/k_diffusion/external.py\", line 112, in forward\n",
            "    eps = self.get_eps(input * c_in, self.sigma_to_t(sigma), **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/src/k-diffusion/k_diffusion/external.py\", line 138, in get_eps\n",
            "    return self.inner_model.apply_model(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/sd_hijack_utils.py\", line 17, in <lambda>\n",
            "    setattr(resolved_obj, func_path[-1], lambda *args, **kwargs: self(*args, **kwargs))\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/sd_hijack_utils.py\", line 28, in __call__\n",
            "    return self.__orig_func(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/ldm/models/diffusion/ddpm.py\", line 858, in apply_model\n",
            "    x_recon = self.model(x_noisy, t, **cond)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/ldm/models/diffusion/ddpm.py\", line 1329, in forward\n",
            "    out = self.diffusion_model(x, t, context=cc)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/ldm/modules/diffusionmodules/openaimodel.py\", line 776, in forward\n",
            "    h = module(h, emb, context)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/ldm/modules/diffusionmodules/openaimodel.py\", line 84, in forward\n",
            "    x = layer(x, context)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/ldm/modules/attention.py\", line 334, in forward\n",
            "    x = block(x, context=context[i])\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/ldm/modules/attention.py\", line 269, in forward\n",
            "    return checkpoint(self._forward, (x, context), self.parameters(), self.checkpoint)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/ldm/modules/diffusionmodules/util.py\", line 114, in checkpoint\n",
            "    return CheckpointFunction.apply(func, len(inputs), *args)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/autograd/function.py\", line 506, in apply\n",
            "    return super().apply(*args, **kwargs)  # type: ignore[misc]\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/ldm/modules/diffusionmodules/util.py\", line 129, in forward\n",
            "    output_tensors = ctx.run_function(*ctx.input_tensors)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/ldm/modules/attention.py\", line 273, in _forward\n",
            "    x = self.attn2(self.norm2(x), context=context) + x\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/sd_hijack_optimizations.py\", line 368, in scaled_dot_product_attention_forward\n",
            "    k = k_in.view(batch_size, -1, h, head_dim).transpose(1, 2)\n",
            "RuntimeError: shape '[2, -1, 5, 64]' is invalid for input of size 123200\n",
            "\n",
            "Prompt matrix will create 1 images using a total of 1 batches.\n",
            "Loading model from cache: control_v11p_sd15_canny [d14c016b]\n",
            "Error running process: /content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/controlnet.py\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/scripts.py\", line 409, in process\n",
            "    script.process(p, *script_args)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/controlnet.py\", line 1058, in process\n",
            "    tmp_seed = int(p.all_seeds[0] if p.seed == -1 else max(int(p.seed),0))\n",
            "TypeError: int() argument must be a string, a bytes-like object or a number, not 'list'\n",
            "\n",
            "  0% 0/40 [00:00<?, ?it/s]\n",
            "Error completing request\n",
            "Arguments: ('task(161d62zpooq2v7p)', 'sunny day, mixpunck USSR future alien car, fantastic soviet union sity background, elien landscape, trending on artstation, sharp focus, studio photo, intricate details, highly detailed, by greg rutkowski, red ', '', [], 40, 1, False, False, 1, 4, 6, 196470314.0, -1.0, 0, 0, 0, True, 796, 512, False, 0.7, 2, 'Latent', 0, 0, 0, [], 1, <controlnet.py.UiControlNetUnit object at 0x7f0bd5bf0760>, True, True, 'positive', 'comma', 0, False, False, '', 1, '', 0, '', 0, '', True, False, False, False, 0, None, False, 50) {}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/call_queue.py\", line 56, in f\n",
            "    res = list(func(*args, **kwargs))\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/call_queue.py\", line 37, in f\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/txt2img.py\", line 53, in txt2img\n",
            "    processed = modules.scripts.scripts_txt2img.run(p, *args)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/scripts.py\", line 399, in run\n",
            "    processed = script.run(p, *script_args)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/scripts/prompt_matrix.py\", line 100, in run\n",
            "    processed = process_images(p)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/processing.py\", line 486, in process_images\n",
            "    res = process_images_inner(p)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/batch_hijack.py\", line 42, in processing_process_images_hijack\n",
            "    return getattr(processing, '__controlnet_original_process_images_inner')(p, *args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/processing.py\", line 636, in process_images_inner\n",
            "    samples_ddim = p.sample(conditioning=c, unconditional_conditioning=uc, seeds=seeds, subseeds=subseeds, subseed_strength=p.subseed_strength, prompts=prompts)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/processing.py\", line 836, in sample\n",
            "    samples = self.sampler.sample(self, x, conditioning, unconditional_conditioning, image_conditioning=self.txt2img_image_conditioning(x))\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/sd_samplers_kdiffusion.py\", line 351, in sample\n",
            "    samples = self.launch_sampling(steps, lambda: self.func(self.model_wrap_cfg, x, extra_args={\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/sd_samplers_kdiffusion.py\", line 227, in launch_sampling\n",
            "    return func()\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/sd_samplers_kdiffusion.py\", line 351, in <lambda>\n",
            "    samples = self.launch_sampling(steps, lambda: self.func(self.model_wrap_cfg, x, extra_args={\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/src/k-diffusion/k_diffusion/sampling.py\", line 128, in sample_euler\n",
            "    denoised = model(x, sigma_hat * s_in, **extra_args)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/sd_samplers_kdiffusion.py\", line 119, in forward\n",
            "    x_out = self.inner_model(x_in, sigma_in, cond={\"c_crossattn\": [cond_in], \"c_concat\": [image_cond_in]})\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/src/k-diffusion/k_diffusion/external.py\", line 112, in forward\n",
            "    eps = self.get_eps(input * c_in, self.sigma_to_t(sigma), **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/src/k-diffusion/k_diffusion/external.py\", line 138, in get_eps\n",
            "    return self.inner_model.apply_model(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/sd_hijack_utils.py\", line 17, in <lambda>\n",
            "    setattr(resolved_obj, func_path[-1], lambda *args, **kwargs: self(*args, **kwargs))\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/sd_hijack_utils.py\", line 28, in __call__\n",
            "    return self.__orig_func(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/ldm/models/diffusion/ddpm.py\", line 858, in apply_model\n",
            "    x_recon = self.model(x_noisy, t, **cond)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/ldm/models/diffusion/ddpm.py\", line 1329, in forward\n",
            "    out = self.diffusion_model(x, t, context=cc)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/ldm/modules/diffusionmodules/openaimodel.py\", line 776, in forward\n",
            "    h = module(h, emb, context)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/ldm/modules/diffusionmodules/openaimodel.py\", line 84, in forward\n",
            "    x = layer(x, context)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/ldm/modules/attention.py\", line 334, in forward\n",
            "    x = block(x, context=context[i])\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/ldm/modules/attention.py\", line 269, in forward\n",
            "    return checkpoint(self._forward, (x, context), self.parameters(), self.checkpoint)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/ldm/modules/diffusionmodules/util.py\", line 114, in checkpoint\n",
            "    return CheckpointFunction.apply(func, len(inputs), *args)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/autograd/function.py\", line 506, in apply\n",
            "    return super().apply(*args, **kwargs)  # type: ignore[misc]\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/ldm/modules/diffusionmodules/util.py\", line 129, in forward\n",
            "    output_tensors = ctx.run_function(*ctx.input_tensors)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/ldm/modules/attention.py\", line 273, in _forward\n",
            "    x = self.attn2(self.norm2(x), context=context) + x\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/sd_hijack_optimizations.py\", line 368, in scaled_dot_product_attention_forward\n",
            "    k = k_in.view(batch_size, -1, h, head_dim).transpose(1, 2)\n",
            "RuntimeError: shape '[2, -1, 5, 64]' is invalid for input of size 123200\n",
            "\n",
            "Prompt matrix will create 1 images using a total of 1 batches.\n",
            "Loading model from cache: control_v11p_sd15_canny [d14c016b]\n",
            "Error running process: /content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/controlnet.py\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/scripts.py\", line 409, in process\n",
            "    script.process(p, *script_args)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/controlnet.py\", line 1058, in process\n",
            "    tmp_seed = int(p.all_seeds[0] if p.seed == -1 else max(int(p.seed),0))\n",
            "TypeError: int() argument must be a string, a bytes-like object or a number, not 'list'\n",
            "\n",
            "  0% 0/40 [00:00<?, ?it/s]\n",
            "Error completing request\n",
            "Arguments: ('task(jtfbg8k8rk0k3w4)', 'sunny day, mixpunck USSR future alien car, fantastic soviet union sity background, elien landscape, trending on artstation, sharp focus, studio photo, intricate details, highly detailed, by greg rutkowski, red ', '', [], 40, 1, False, False, 1, 4, 6, 196470314.0, -1.0, 0, 0, 0, False, 796, 512, False, 0.7, 2, 'Latent', 0, 0, 0, [], 1, <controlnet.py.UiControlNetUnit object at 0x7f0b8ba930a0>, True, True, 'positive', 'comma', 0, False, False, '', 1, '', 0, '', 0, '', True, False, False, False, 0, None, False, 50) {}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/call_queue.py\", line 56, in f\n",
            "    res = list(func(*args, **kwargs))\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/call_queue.py\", line 37, in f\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/txt2img.py\", line 53, in txt2img\n",
            "    processed = modules.scripts.scripts_txt2img.run(p, *args)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/scripts.py\", line 399, in run\n",
            "    processed = script.run(p, *script_args)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/scripts/prompt_matrix.py\", line 100, in run\n",
            "    processed = process_images(p)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/processing.py\", line 486, in process_images\n",
            "    res = process_images_inner(p)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/batch_hijack.py\", line 42, in processing_process_images_hijack\n",
            "    return getattr(processing, '__controlnet_original_process_images_inner')(p, *args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/processing.py\", line 636, in process_images_inner\n",
            "    samples_ddim = p.sample(conditioning=c, unconditional_conditioning=uc, seeds=seeds, subseeds=subseeds, subseed_strength=p.subseed_strength, prompts=prompts)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/processing.py\", line 836, in sample\n",
            "    samples = self.sampler.sample(self, x, conditioning, unconditional_conditioning, image_conditioning=self.txt2img_image_conditioning(x))\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/sd_samplers_kdiffusion.py\", line 351, in sample\n",
            "    samples = self.launch_sampling(steps, lambda: self.func(self.model_wrap_cfg, x, extra_args={\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/sd_samplers_kdiffusion.py\", line 227, in launch_sampling\n",
            "    return func()\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/sd_samplers_kdiffusion.py\", line 351, in <lambda>\n",
            "    samples = self.launch_sampling(steps, lambda: self.func(self.model_wrap_cfg, x, extra_args={\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/src/k-diffusion/k_diffusion/sampling.py\", line 128, in sample_euler\n",
            "    denoised = model(x, sigma_hat * s_in, **extra_args)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/sd_samplers_kdiffusion.py\", line 119, in forward\n",
            "    x_out = self.inner_model(x_in, sigma_in, cond={\"c_crossattn\": [cond_in], \"c_concat\": [image_cond_in]})\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/src/k-diffusion/k_diffusion/external.py\", line 112, in forward\n",
            "    eps = self.get_eps(input * c_in, self.sigma_to_t(sigma), **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/src/k-diffusion/k_diffusion/external.py\", line 138, in get_eps\n",
            "    return self.inner_model.apply_model(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/sd_hijack_utils.py\", line 17, in <lambda>\n",
            "    setattr(resolved_obj, func_path[-1], lambda *args, **kwargs: self(*args, **kwargs))\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/sd_hijack_utils.py\", line 28, in __call__\n",
            "    return self.__orig_func(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/ldm/models/diffusion/ddpm.py\", line 858, in apply_model\n",
            "    x_recon = self.model(x_noisy, t, **cond)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/ldm/models/diffusion/ddpm.py\", line 1329, in forward\n",
            "    out = self.diffusion_model(x, t, context=cc)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/ldm/modules/diffusionmodules/openaimodel.py\", line 776, in forward\n",
            "    h = module(h, emb, context)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/ldm/modules/diffusionmodules/openaimodel.py\", line 84, in forward\n",
            "    x = layer(x, context)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/ldm/modules/attention.py\", line 334, in forward\n",
            "    x = block(x, context=context[i])\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/ldm/modules/attention.py\", line 269, in forward\n",
            "    return checkpoint(self._forward, (x, context), self.parameters(), self.checkpoint)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/ldm/modules/diffusionmodules/util.py\", line 114, in checkpoint\n",
            "    return CheckpointFunction.apply(func, len(inputs), *args)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/autograd/function.py\", line 506, in apply\n",
            "    return super().apply(*args, **kwargs)  # type: ignore[misc]\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/ldm/modules/diffusionmodules/util.py\", line 129, in forward\n",
            "    output_tensors = ctx.run_function(*ctx.input_tensors)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/ldm/modules/attention.py\", line 273, in _forward\n",
            "    x = self.attn2(self.norm2(x), context=context) + x\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/sd_hijack_optimizations.py\", line 368, in scaled_dot_product_attention_forward\n",
            "    k = k_in.view(batch_size, -1, h, head_dim).transpose(1, 2)\n",
            "RuntimeError: shape '[2, -1, 5, 64]' is invalid for input of size 123200\n",
            "\n",
            "Prompt matrix will create 1 images using a total of 1 batches.\n",
            "Loading model from cache: control_v11p_sd15_canny [d14c016b]\n",
            "Error running process: /content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/controlnet.py\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/scripts.py\", line 409, in process\n",
            "    script.process(p, *script_args)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/controlnet.py\", line 992, in process\n",
            "    raise ValueError('controlnet is enabled but no input image is given')\n",
            "ValueError: controlnet is enabled but no input image is given\n",
            "\n",
            "  0% 0/40 [00:00<?, ?it/s]\n",
            "Error completing request\n",
            "Arguments: ('task(2mmpr6lnlfwcx4l)', 'sunny day, mixpunck USSR future alien car, fantastic soviet union sity background, elien landscape, trending on artstation, sharp focus, studio photo, intricate details, highly detailed, by greg rutkowski, red ', '', [], 40, 1, False, False, 1, 4, 6, 196470314.0, -1.0, 0, 0, 0, False, 796, 512, False, 0.7, 2, 'Latent', 0, 0, 0, [], 1, <controlnet.py.UiControlNetUnit object at 0x7f0b8ba6f910>, True, True, 'positive', 'comma', 0, False, False, '', 1, '', 0, '', 0, '', True, False, False, False, 0, None, False, 50) {}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/call_queue.py\", line 56, in f\n",
            "    res = list(func(*args, **kwargs))\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/call_queue.py\", line 37, in f\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/txt2img.py\", line 53, in txt2img\n",
            "    processed = modules.scripts.scripts_txt2img.run(p, *args)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/scripts.py\", line 399, in run\n",
            "    processed = script.run(p, *script_args)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/scripts/prompt_matrix.py\", line 100, in run\n",
            "    processed = process_images(p)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/processing.py\", line 486, in process_images\n",
            "    res = process_images_inner(p)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/batch_hijack.py\", line 42, in processing_process_images_hijack\n",
            "    return getattr(processing, '__controlnet_original_process_images_inner')(p, *args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/processing.py\", line 636, in process_images_inner\n",
            "    samples_ddim = p.sample(conditioning=c, unconditional_conditioning=uc, seeds=seeds, subseeds=subseeds, subseed_strength=p.subseed_strength, prompts=prompts)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/processing.py\", line 836, in sample\n",
            "    samples = self.sampler.sample(self, x, conditioning, unconditional_conditioning, image_conditioning=self.txt2img_image_conditioning(x))\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/sd_samplers_kdiffusion.py\", line 351, in sample\n",
            "    samples = self.launch_sampling(steps, lambda: self.func(self.model_wrap_cfg, x, extra_args={\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/sd_samplers_kdiffusion.py\", line 227, in launch_sampling\n",
            "    return func()\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/sd_samplers_kdiffusion.py\", line 351, in <lambda>\n",
            "    samples = self.launch_sampling(steps, lambda: self.func(self.model_wrap_cfg, x, extra_args={\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/src/k-diffusion/k_diffusion/sampling.py\", line 128, in sample_euler\n",
            "    denoised = model(x, sigma_hat * s_in, **extra_args)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/sd_samplers_kdiffusion.py\", line 119, in forward\n",
            "    x_out = self.inner_model(x_in, sigma_in, cond={\"c_crossattn\": [cond_in], \"c_concat\": [image_cond_in]})\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/src/k-diffusion/k_diffusion/external.py\", line 112, in forward\n",
            "    eps = self.get_eps(input * c_in, self.sigma_to_t(sigma), **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/src/k-diffusion/k_diffusion/external.py\", line 138, in get_eps\n",
            "    return self.inner_model.apply_model(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/sd_hijack_utils.py\", line 17, in <lambda>\n",
            "    setattr(resolved_obj, func_path[-1], lambda *args, **kwargs: self(*args, **kwargs))\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/sd_hijack_utils.py\", line 28, in __call__\n",
            "    return self.__orig_func(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/ldm/models/diffusion/ddpm.py\", line 858, in apply_model\n",
            "    x_recon = self.model(x_noisy, t, **cond)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/ldm/models/diffusion/ddpm.py\", line 1329, in forward\n",
            "    out = self.diffusion_model(x, t, context=cc)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/ldm/modules/diffusionmodules/openaimodel.py\", line 776, in forward\n",
            "    h = module(h, emb, context)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/ldm/modules/diffusionmodules/openaimodel.py\", line 84, in forward\n",
            "    x = layer(x, context)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/ldm/modules/attention.py\", line 334, in forward\n",
            "    x = block(x, context=context[i])\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/ldm/modules/attention.py\", line 269, in forward\n",
            "    return checkpoint(self._forward, (x, context), self.parameters(), self.checkpoint)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/ldm/modules/diffusionmodules/util.py\", line 114, in checkpoint\n",
            "    return CheckpointFunction.apply(func, len(inputs), *args)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/autograd/function.py\", line 506, in apply\n",
            "    return super().apply(*args, **kwargs)  # type: ignore[misc]\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/ldm/modules/diffusionmodules/util.py\", line 129, in forward\n",
            "    output_tensors = ctx.run_function(*ctx.input_tensors)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/ldm/modules/attention.py\", line 273, in _forward\n",
            "    x = self.attn2(self.norm2(x), context=context) + x\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/sd_hijack_optimizations.py\", line 368, in scaled_dot_product_attention_forward\n",
            "    k = k_in.view(batch_size, -1, h, head_dim).transpose(1, 2)\n",
            "RuntimeError: shape '[2, -1, 5, 64]' is invalid for input of size 123200\n",
            "\n",
            "Prompt matrix will create 1 images using a total of 1 batches.\n",
            "  0% 0/62 [00:00<?, ?it/s]\n",
            "Error completing request\n",
            "Arguments: ('task(5pmf8bn5mtg11da)', 'sunny day, mixpunck USSR future alien car, fantastic soviet union sity background, elien landscape, trending on artstation, sharp focus, studio photo, intricate details, highly detailed, by greg rutkowski, red ', '', [], 62, 1, False, False, 1, 4, 6, 196470314.0, -1.0, 0, 0, 0, False, 796, 512, False, 0.7, 2, 'Latent', 0, 0, 0, [], 1, <controlnet.py.UiControlNetUnit object at 0x7f0a7c1ed280>, False, False, 'positive', 'comma', 0, False, False, '', 1, '', 0, '', 0, '', True, False, False, False, 0, None, False, 50) {}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/call_queue.py\", line 56, in f\n",
            "    res = list(func(*args, **kwargs))\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/call_queue.py\", line 37, in f\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/txt2img.py\", line 53, in txt2img\n",
            "    processed = modules.scripts.scripts_txt2img.run(p, *args)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/scripts.py\", line 399, in run\n",
            "    processed = script.run(p, *script_args)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/scripts/prompt_matrix.py\", line 100, in run\n",
            "    processed = process_images(p)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/processing.py\", line 486, in process_images\n",
            "    res = process_images_inner(p)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/scripts/batch_hijack.py\", line 42, in processing_process_images_hijack\n",
            "    return getattr(processing, '__controlnet_original_process_images_inner')(p, *args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/processing.py\", line 636, in process_images_inner\n",
            "    samples_ddim = p.sample(conditioning=c, unconditional_conditioning=uc, seeds=seeds, subseeds=subseeds, subseed_strength=p.subseed_strength, prompts=prompts)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/processing.py\", line 836, in sample\n",
            "    samples = self.sampler.sample(self, x, conditioning, unconditional_conditioning, image_conditioning=self.txt2img_image_conditioning(x))\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/sd_samplers_kdiffusion.py\", line 351, in sample\n",
            "    samples = self.launch_sampling(steps, lambda: self.func(self.model_wrap_cfg, x, extra_args={\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/sd_samplers_kdiffusion.py\", line 227, in launch_sampling\n",
            "    return func()\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/sd_samplers_kdiffusion.py\", line 351, in <lambda>\n",
            "    samples = self.launch_sampling(steps, lambda: self.func(self.model_wrap_cfg, x, extra_args={\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/src/k-diffusion/k_diffusion/sampling.py\", line 128, in sample_euler\n",
            "    denoised = model(x, sigma_hat * s_in, **extra_args)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/sd_samplers_kdiffusion.py\", line 119, in forward\n",
            "    x_out = self.inner_model(x_in, sigma_in, cond={\"c_crossattn\": [cond_in], \"c_concat\": [image_cond_in]})\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/src/k-diffusion/k_diffusion/external.py\", line 112, in forward\n",
            "    eps = self.get_eps(input * c_in, self.sigma_to_t(sigma), **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/src/k-diffusion/k_diffusion/external.py\", line 138, in get_eps\n",
            "    return self.inner_model.apply_model(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/sd_hijack_utils.py\", line 17, in <lambda>\n",
            "    setattr(resolved_obj, func_path[-1], lambda *args, **kwargs: self(*args, **kwargs))\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/sd_hijack_utils.py\", line 28, in __call__\n",
            "    return self.__orig_func(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/ldm/models/diffusion/ddpm.py\", line 858, in apply_model\n",
            "    x_recon = self.model(x_noisy, t, **cond)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/ldm/models/diffusion/ddpm.py\", line 1329, in forward\n",
            "    out = self.diffusion_model(x, t, context=cc)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/ldm/modules/diffusionmodules/openaimodel.py\", line 776, in forward\n",
            "    h = module(h, emb, context)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/ldm/modules/diffusionmodules/openaimodel.py\", line 84, in forward\n",
            "    x = layer(x, context)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/ldm/modules/attention.py\", line 334, in forward\n",
            "    x = block(x, context=context[i])\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/ldm/modules/attention.py\", line 269, in forward\n",
            "    return checkpoint(self._forward, (x, context), self.parameters(), self.checkpoint)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/ldm/modules/diffusionmodules/util.py\", line 114, in checkpoint\n",
            "    return CheckpointFunction.apply(func, len(inputs), *args)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/autograd/function.py\", line 506, in apply\n",
            "    return super().apply(*args, **kwargs)  # type: ignore[misc]\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/ldm/modules/diffusionmodules/util.py\", line 129, in forward\n",
            "    output_tensors = ctx.run_function(*ctx.input_tensors)\n",
            "  File \"/content/gdrive/MyDrive/sd/stablediffusion/ldm/modules/attention.py\", line 273, in _forward\n",
            "    x = self.attn2(self.norm2(x), context=context) + x\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/sd_hijack_optimizations.py\", line 368, in scaled_dot_product_attention_forward\n",
            "    k = k_in.view(batch_size, -1, h, head_dim).transpose(1, 2)\n",
            "RuntimeError: shape '[2, -1, 5, 64]' is invalid for input of size 123200\n",
            "\n",
            "100% 20/20 [00:03<00:00,  5.93it/s]\n",
            "100% 20/20 [00:03<00:00,  5.97it/s]\n",
            "100% 20/20 [00:03<00:00,  5.98it/s]\n",
            "100% 51/51 [00:08<00:00,  5.95it/s]\n",
            "100% 51/51 [00:08<00:00,  6.04it/s]\n",
            "100% 51/51 [00:08<00:00,  5.95it/s]\n",
            "100% 51/51 [00:08<00:00,  5.86it/s]\n",
            "100% 51/51 [00:08<00:00,  6.14it/s]\n",
            "100% 65/65 [00:10<00:00,  5.96it/s]\n",
            "100% 65/65 [00:10<00:00,  6.01it/s]\n",
            "100% 65/65 [00:21<00:00,  3.03it/s]\n",
            "100% 65/65 [00:21<00:00,  3.02it/s]\n",
            "100% 65/65 [00:21<00:00,  3.02it/s]\n"
          ]
        }
      ],
      "source": [
        "#@markdown # Start Stable-Diffusion\n",
        "from IPython.utils import capture\n",
        "import time\n",
        "import sys\n",
        "import fileinput\n",
        "from pyngrok import ngrok, conf\n",
        "\n",
        "Use_Cloudflare_Tunnel = False #@param {type:\"boolean\"}\n",
        "#@markdown - Offers better gradio responsivity\n",
        "\n",
        "Ngrok_token = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown - Input your ngrok token if you want to use ngrok server\n",
        "\n",
        "User = \"\" #@param {type:\"string\"}\n",
        "Password= \"\" #@param {type:\"string\"}\n",
        "#@markdown - Add credentials to your Gradio interface (optional)\n",
        "\n",
        "auth=f\"--gradio-auth {User}:{Password}\"\n",
        "if User ==\"\" or Password==\"\":\n",
        "  auth=\"\"\n",
        "\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd /content/gdrive/$mainpth/sd/stable-diffusion-$blasphemy/modules/\n",
        "\n",
        "  if Use_Latest_Working_Commit:\n",
        "    !wget -q -O paths.py https://github.com/TheLastBen/fast-stable-diffusion/raw/5632d2ef7fffd940976538d270854ec4faf26855/AUTOMATIC1111_files/paths.py\n",
        "    !wget -q -O extras.py https://github.com/AUTOMATIC1111/stable-diffusion-$blasphemy/raw/a9eab236d7e8afa4d6205127904a385b2c43bb24/modules/extras.py\n",
        "    !wget -q -O sd_models.py https://github.com/AUTOMATIC1111/stable-diffusion-$blasphemy/raw/a9eab236d7e8afa4d6205127904a385b2c43bb24/modules/sd_models.py\n",
        "    !wget -q -O /usr/local/lib/python3.9/dist-packages/gradio/blocks.py https://github.com/TheLastBen/fast-stable-diffusion/raw/7ff88eaa1fb4997bacd9845bd487f9a14335d625/AUTOMATIC1111_files/blocks.py \n",
        "  else:\n",
        "    !wget -q -O paths.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/AUTOMATIC1111_files/paths.py\n",
        "    !wget -q -O extras.py https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-$blasphemy/master/modules/extras.py\n",
        "    !wget -q -O sd_models.py https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-$blasphemy/master/modules/sd_models.py\n",
        "    !wget -q -O /usr/local/lib/python3.9/dist-packages/gradio/blocks.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/AUTOMATIC1111_files/blocks.py\n",
        "  %cd /content/gdrive/$mainpth/sd/stable-diffusion-$blasphemy/\n",
        "\n",
        "  !sed -i \"s@os.path.splitext(checkpoint_file)@os.path.splitext(checkpoint_file); map_location='cuda'@\" /content/gdrive/$mainpth/sd/stable-diffusion-$blasphemy/modules/sd_models.py\n",
        "  !sed -i 's@ui.create_ui().*@ui.create_ui();shared.demo.queue(concurrency_count=999999,status_update_rate=0.1)@' /content/gdrive/$mainpth/sd/stable-diffusion-$blasphemy/webui.py\n",
        "  !sed -i \"s@map_location='cpu'@map_location='cuda'@\" /content/gdrive/$mainpth/sd/stable-diffusion-$blasphemy/modules/extras.py\n",
        "  !sed -i 's@/content/gdrive/MyDrive/sd/stablediffusion@/content/gdrive/{mainpth}/sd/stablediffusion@' /content/gdrive/$mainpth/sd/stable-diffusion-$blasphemy/modules/paths.py\n",
        "  !sed -i 's@print(\\\"No module.*@@' /content/gdrive/$mainpth/sd/stablediffusion/ldm/modules/diffusionmodules/model.py\n",
        "  !sed -i 's@\\\"quicksettings\\\": OptionInfo(.*@\"quicksettings\": OptionInfo(\"sd_model_checkpoint,  sd_vae, CLIP_stop_at_last_layers, inpainting_mask_weight, initial_noise_multiplier\", \"Quicksettings list\"),@' /content/gdrive/$mainpth/sd/stable-diffusion-$blasphemy/modules/shared.py\n",
        "\n",
        "share=''\n",
        "if Ngrok_token!=\"\":\n",
        "  ngrok.kill()\n",
        "  srv=ngrok.connect(7860, pyngrok_config=conf.PyngrokConfig(auth_token=Ngrok_token) , bind_tls=True).public_url\n",
        "\n",
        "  for line in fileinput.input('/usr/local/lib/python3.9/dist-packages/gradio/blocks.py', inplace=True):\n",
        "    if line.strip().startswith('self.server_name ='):\n",
        "        line = f'            self.server_name = \"{srv[8:]}\"\\n'\n",
        "    if line.strip().startswith('self.protocol = \"https\"'):\n",
        "        line = '            self.protocol = \"https\"\\n'\n",
        "    if line.strip().startswith('if self.local_url.startswith(\"https\") or self.is_colab'):\n",
        "        line = ''\n",
        "    if line.strip().startswith('else \"http\"'):\n",
        "        line = ''\n",
        "    sys.stdout.write(line)\n",
        "\n",
        "elif Use_Cloudflare_Tunnel:\n",
        "  with capture.capture_output() as cap:\n",
        "    !pkill cloudflared\n",
        "    time.sleep(4)\n",
        "    !nohup cloudflared tunnel --url http://localhost:7860 > /content/srv.txt 2>&1 &\n",
        "    time.sleep(4)\n",
        "    !grep -o 'https[^[:space:]]*\\.trycloudflare.com' /content/srv.txt >/content/srvr.txt\n",
        "    time.sleep(2)\n",
        "    srv= getoutput('cat /content/srvr.txt')\n",
        "\n",
        "    for line in fileinput.input('/usr/local/lib/python3.9/dist-packages/gradio/blocks.py', inplace=True):\n",
        "      if line.strip().startswith('self.server_name ='):\n",
        "          line = f'            self.server_name = \"{srv[8:]}\"\\n'\n",
        "      if line.strip().startswith('self.protocol = \"https\"'):\n",
        "          line = '            self.protocol = \"https\"\\n'\n",
        "      if line.strip().startswith('if self.local_url.startswith(\"https\") or self.is_colab'):\n",
        "          line = ''\n",
        "      if line.strip().startswith('else \"http\"'):\n",
        "          line = ''\n",
        "      sys.stdout.write(line)\n",
        "            \n",
        "    !rm /content/srv.txt /content/srvr.txt\n",
        "\n",
        "else:\n",
        "  share='--share'\n",
        "\n",
        "try:\n",
        "  model\n",
        "  if os.path.isfile(model):\n",
        "    !python /content/gdrive/$mainpth/sd/stable-diffusion-$blasphemy/webui.py $share --api --disable-safe-unpickle --enable-insecure-extension-access --no-download-sd-model --no-half-vae  --ckpt \"$model\" --opt-sdp-attention $auth --disable-console-progressbars \n",
        "  else:\n",
        "    !python /content/gdrive/$mainpth/sd/stable-diffusion-$blasphemy/webui.py $share --api --disable-safe-unpickle --enable-insecure-extension-access --no-download-sd-model --no-half-vae  --ckpt-dir \"$model\" --opt-sdp-attention $auth --disable-console-progressbars \n",
        "except:\n",
        "   !python /content/gdrive/$mainpth/sd/stable-diffusion-$blasphemy/webui.py $share --api --disable-safe-unpickle --enable-insecure-extension-access --no-download-sd-model --no-half-vae --opt-sdp-attention $auth --disable-console-progressbars"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "852f3d4a6c7448c7ba8dc133d7553ffa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "✔ Done",
            "disabled": true,
            "icon": "",
            "layout": "IPY_MODEL_bf021d36d0024b398b944fce0f8e28a5",
            "style": "IPY_MODEL_638cc306969c4a8cbe5ed094123bde72",
            "tooltip": ""
          }
        },
        "bf021d36d0024b398b944fce0f8e28a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": "50px",
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "638cc306969c4a8cbe5ed094123bde72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "9745dd2e4ca8469aa13644d0222becca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "✔ Done",
            "disabled": true,
            "icon": "",
            "layout": "IPY_MODEL_766b8b8b86c240c3b60a79b37e59046b",
            "style": "IPY_MODEL_700bc180578540d394c6eb8dffd2d6b7",
            "tooltip": ""
          }
        },
        "766b8b8b86c240c3b60a79b37e59046b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": "50px",
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "700bc180578540d394c6eb8dffd2d6b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "687c5aa5c25f453ea759699f02cc3ed8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "✔ Done",
            "disabled": true,
            "icon": "",
            "layout": "IPY_MODEL_d7f17c693e73462c96f8216ac1318683",
            "style": "IPY_MODEL_435109afd3b84a30a09bf8a05a9ce511",
            "tooltip": ""
          }
        },
        "d7f17c693e73462c96f8216ac1318683": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": "50px",
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "435109afd3b84a30a09bf8a05a9ce511": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "4ebfd7f28576471a984a025826cd8ca9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "✔ Done",
            "disabled": true,
            "icon": "",
            "layout": "IPY_MODEL_d29f63eb692c416ab3610490e21278a7",
            "style": "IPY_MODEL_424945226ce64cfd9b9d1e67c445c5d0",
            "tooltip": ""
          }
        },
        "d29f63eb692c416ab3610490e21278a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": "50px",
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "424945226ce64cfd9b9d1e67c445c5d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}